{
    "model_kwargs":{
    "teacher_lang_model":"gpt2-medium",
    "student_lang_model":"gpt2",
        "generation_kwargs":{
            "max_generation_length":256, 
            "num_beams":5, 
            "early_stopping":true
        },    
    "teacher_gpu_device_id":5,
    "student_gpu_device_id":6,
    "teacher_model_ckpt_path":"",
    "student_model_ckpt_path":""
    },

    "dataset_kwargs":{
        "_type":"cnn_dailymail",
        "cnn_dataset_kwargs": {
            "data_dir":"data",
            "train_dataset":"subset_train.csv",
            "validation_dataset":"subset_val.csv",
            "validation_subset":"subset_val.csv",
            "train_batch_size":24,
            "val_batch_size":4
        }
    }, 
    "ppo_kwargs": {
        "teacher_mixed_sample":false,
        "temperature":1.0,
        "reward_scaling":0.5,
        "reward_cliprange":100,
        "seed_ppo":101
    },

    "trainer_kwargs": {
        "output_dir":"teacher_finetune_dir/gpt2-medium",
        "training_epochs":10,
        "ppo_epochs":4,
        "kd_ratio":0.5,
        "gradient_accumulation_steps":0,
        "gradient_clipping": 1.0        
    },
    "optimizer_kwargs": {
        "default_lr": 1e-5,
        "type": "AdamW",
        "kwargs": {
            "weight_decay": 0.1,
            "amsgrad": true
        },
        "lm_lr": 1e-5        
    },
    "lr_scheduler_kwargs": {
        "_type": "linear_lr_warmup",
        "increase_batch_size_on_plateau": false,
        "num_warmup_steps": 200,
        "num_training_steps": -1,
        "max_warmup_steps": 1000
    }    
}